## 打开jupyter

```
jupyter notebook
```

卷积层涉及的参数

```
1.滑动窗口步长
2.卷积核尺寸
3.边缘填充
4.卷积核个数
```

需要掌握知识

```
https://mp.weixin.qq.com/s/ihRXv2X2lcAmVj3-wJ_RkQ
```

## 本地运行llama3

```
ollama run llama3
ollama run llama3.1:70b
```

## CV2-API

### 读取图片

```python
img=cv2.imread('cat.jpg'，cv2.IMREAD_GRAYSCALE)   #显示为灰度
```

### 展示图片

```python
cv2.imshow('image',img) 
```

### 等待图片销毁时间

```python
cv2.waitKey(0)     #0代表任意键
cv2.destroyAllWindows()
```

### 查看图片的形状

```python
img.shape
```

### 保存图片

```python
cv2.imwrite('mycat.png',img)
```

### 查看图片类型

```python
type(img)
```

### 查看图片像素大小

```python
img.size
```

### 读取视频

```python
vc = cv2.VideoCapture('test.mp4')
```

### 检查图片打开是否正常

```python
if vc.isOpened(): 
    open, frame = vc.read()
else:
    open = False
```

### 读取视频并展示

```python
while open:
    ret, frame = vc.read()
    if frame is None:
        break
    if ret == True:
        gray = cv2.cvtColor(frame,  cv2.COLOR_BGR2GRAY)
        cv2.imshow('result', gray)
        if cv2.waitKey(100) & 0xFF == 27:
            break
vc.release()
cv2.destroyAllWindows()
```

### 截取图片部分并展示

```python
img=cv2.imread('cat.jpg')
cat=img[0:50,0:200] 
cv_show('cat',cat)
```

### 图片大小准换

```python
img_dog = cv2.resize(img_dog, (500, 414))
res = cv2.resize(img, (0, 0), fx=4, fy=4)   # x*4  y*4
```

### 将两张图片融合

```python
img_cat=cv2.imread('cat.jpg')
img_dog=cv2.imread('dog.jpg')
res = cv2.addWeighted(img_cat, 0.4, img_dog, 0.6, 0)   # 0.4代表img_cat的权重，0.6代表img_dog的权重
```

### 划线

```
cv2.line(frame, (0, int(frame_height / 2)), (int(frame_width), int(frame_height / 2)), (0, 0, 255), 2)
```

### 画框

```
cv2.polylines(frame, [pts], True, (0, 0, 255), 2)
```



## 图像处理

### 灰度图


```python
import cv2 #opencv读取的格式是BGR
import numpy as np
import matplotlib.pyplot as plt#Matplotlib是RGB
%matplotlib inline 

img=cv2.imread('cat.jpg')
img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
img_gray.shape
```




    (414, 500)


cv2.imshow("img_gray", img_gray)
cv2.waitKey(0)    
cv2.destroyAllWindows() 

### HSV

- H - 色调（主波长）。 
- S - 饱和度（纯度/颜色的阴影）。 
- V值（强度）


```python
hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)

cv2.imshow("hsv", hsv)
cv2.waitKey(0)    
cv2.destroyAllWindows()
```

### 图像阈值

#### ret, dst = cv2.threshold(src, thresh, maxval, type)

- src： 输入图，只能输入单通道图像，通常来说为灰度图
- dst： 输出图
- thresh： 阈值
- maxval： 当像素值超过了阈值（或者小于阈值，根据type来决定），所赋予的值
- type：二值化操作的类型，包含以下5种类型： cv2.THRESH_BINARY； cv2.THRESH_BINARY_INV； cv2.THRESH_TRUNC； cv2.THRESH_TOZERO；cv2.THRESH_TOZERO_INV

- cv2.THRESH_BINARY           超过阈值部分取maxval（最大值），否则取0
- cv2.THRESH_BINARY_INV    THRESH_BINARY的反转
- cv2.THRESH_TRUNC            大于阈值部分设为阈值，否则不变
- cv2.THRESH_TOZERO          大于阈值部分不改变，否则设为0
- cv2.THRESH_TOZERO_INV  THRESH_TOZERO的反转




```python
ret, thresh1 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)
ret, thresh2 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY_INV)
ret, thresh3 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TRUNC)
ret, thresh4 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TOZERO)
ret, thresh5 = cv2.threshold(img_gray, 127, 255, cv2.THRESH_TOZERO_INV)

titles = ['Original Image', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']
images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]

for i in range(6):
    plt.subplot(2, 3, i + 1), plt.imshow(images[i], 'gray')
    plt.title(titles[i])
    plt.xticks([]), plt.yticks([])
plt.show()
```


![png](C:\Users\Administrator\Downloads\图像处理\output_6_0.png)


### 图像平滑

![D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\image.png](attachment:image.png)


```python
img = cv2.imread('lenaNoise.png')

cv2.imshow('img', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
# 均值滤波
# 简单的平均卷积操作
blur = cv2.blur(img, (3, 3))

cv2.imshow('blur', blur)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
# 方框滤波
# 基本和均值一样，可以选择归一化
box = cv2.boxFilter(img,-1,(3,3), normalize=True)  

cv2.imshow('box', box)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
# 方框滤波
# 基本和均值一样，可以选择归一化,容易越界
box = cv2.boxFilter(img,-1,(3,3), normalize=False)  

cv2.imshow('box', box)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
# 高斯滤波
# 高斯模糊的卷积核里的数值是满足高斯分布，相当于更重视中间的
aussian = cv2.GaussianBlur(img, (5, 5), 1)  

cv2.imshow('aussian', aussian)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
# 中值滤波
# 相当于用中值代替
median = cv2.medianBlur(img, 5)  # 中值滤波

cv2.imshow('median', median)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
# 展示所有的
res = np.hstack((blur,aussian,median))
print (res)
cv2.imshow('median vs average', res)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

    [[[125 137 226]
      [128 137 225]
      [129 137 224]
      ...
      [122 145 230]
      [110 130 221]
      [ 90  99 200]]
    
     [[125 137 226]
      [128 137 225]
      [129 137 224]
      ...
      [122 145 230]
      [110 130 221]
      [ 90  99 200]]
    
     [[125 137 226]
      [128 137 225]
      [129 137 224]
      ...
      [122 145 230]
      [110 130 221]
      [ 90  99 200]]
    
     ...
    
     [[ 81  47 103]
      [ 81  50 106]
      [ 60  25  90]
      ...
      [ 79  67 173]
      [ 79  67 174]
      [ 81  68 177]]
    
     [[ 80  47 102]
      [ 81  50 106]
      [ 74  26  90]
      ...
      [ 81  70 177]
      [ 81  70 177]
      [ 81  71 179]]
    
     [[ 57  22  82]
      [ 59  25  87]
      [ 75  27  90]
      ...
      [ 81  71 177]
      [ 81  71 179]
      [ 81  73 181]]]


### 形态学-腐蚀操作


```python
img = cv2.imread('dige.png')

cv2.imshow('img', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
kernel = np.ones((5,5),np.uint8) 
erosion = cv2.erode(img,kernel,iterations = 1)

cv2.imshow('erosion', erosion)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
pie = cv2.imread('pie.png')

cv2.imshow('pie', pie)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
kernel = np.ones((30,30),np.uint8) 
erosion_1 = cv2.erode(pie,kernel,iterations = 1)
erosion_2 = cv2.erode(pie,kernel,iterations = 2)
erosion_3 = cv2.erode(pie,kernel,iterations = 3)
res = np.hstack((erosion_1,erosion_2,erosion_3))
cv2.imshow('res', res)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 形态学-膨胀操作


```python
img = cv2.imread('dige.png')
cv2.imshow('img', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
kernel = np.ones((3,3),np.uint8) 
dige_erosion = cv2.erode(img,kernel,iterations = 1)

cv2.imshow('erosion', erosion)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
kernel = np.ones((3,3),np.uint8) 
dige_dilate = cv2.dilate(dige_erosion,kernel,iterations = 1)

cv2.imshow('dilate', dige_dilate)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
pie = cv2.imread('pie.png')

kernel = np.ones((30,30),np.uint8) 
dilate_1 = cv2.dilate(pie,kernel,iterations = 1)
dilate_2 = cv2.dilate(pie,kernel,iterations = 2)
dilate_3 = cv2.dilate(pie,kernel,iterations = 3)
res = np.hstack((dilate_1,dilate_2,dilate_3))
cv2.imshow('res', res)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 开运算与闭运算


```python
# 开：先腐蚀，再膨胀
img = cv2.imread('dige.png')

kernel = np.ones((5,5),np.uint8) 
opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)

cv2.imshow('opening', opening)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
# 闭：先膨胀，再腐蚀
img = cv2.imread('dige.png')

kernel = np.ones((5,5),np.uint8) 
closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)

cv2.imshow('closing', closing)
cv2.waitKey(0)
cv2.destroyAllWindows()


```

### 梯度运算


```python
# 梯度=膨胀-腐蚀
pie = cv2.imread('pie.png')
kernel = np.ones((7,7),np.uint8) 
dilate = cv2.dilate(pie,kernel,iterations = 5)
erosion = cv2.erode(pie,kernel,iterations = 5)

res = np.hstack((dilate,erosion))

cv2.imshow('res', res)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
gradient = cv2.morphologyEx(pie, cv2.MORPH_GRADIENT, kernel)

cv2.imshow('gradient', gradient)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 礼帽与黑帽

- 礼帽 = 原始输入-开运算结果
- 黑帽 = 闭运算-原始输入


```python
#礼帽
img = cv2.imread('dige.png')
tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)
cv2.imshow('tophat', tophat)
cv2.waitKey(0)
cv2.destroyAllWindows()
```


```python
#黑帽
img = cv2.imread('dige.png')
blackhat  = cv2.morphologyEx(img,cv2.MORPH_BLACKHAT, kernel)
cv2.imshow('blackhat ', blackhat )
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 图像梯度-Sobel算子

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\sobel_1.png)


```python
img = cv2.imread('pie.png',cv2.IMREAD_GRAYSCALE)
cv2.imshow("img",img)
cv2.waitKey()
cv2.destroyAllWindows()
```

dst = cv2.Sobel(src, ddepth, dx, dy, ksize)

- ddepth:图像的深度
- dx和dy分别表示水平和竖直方向
- ksize是Sobel算子的大小



```python
def cv_show(img,name):
    cv2.imshow(name,img)
    cv2.waitKey()
    cv2.destroyAllWindows()
```


```python
sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)

cv_show(sobelx,'sobelx')
```

白到黑是正数，黑到白就是负数了，所有的负数会被截断成0，所以要取绝对值


```python
sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)
sobelx = cv2.convertScaleAbs(sobelx)
cv_show(sobelx,'sobelx')
```


```python
sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)
sobely = cv2.convertScaleAbs(sobely)  
cv_show(sobely,'sobely')
```

分别计算x和y，再求和


```python
sobelxy = cv2.addWeighted(sobelx,0.5,sobely,0.5,0)
cv_show(sobelxy,'sobelxy')
```

不建议直接计算


```python
sobelxy=cv2.Sobel(img,cv2.CV_64F,1,1,ksize=3)
sobelxy = cv2.convertScaleAbs(sobelxy) 
cv_show(sobelxy,'sobelxy')
```


```python
img = cv2.imread('lena.jpg',cv2.IMREAD_GRAYSCALE)
cv_show(img,'img')
```


```python
img = cv2.imread('lena.jpg',cv2.IMREAD_GRAYSCALE)
sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)
sobelx = cv2.convertScaleAbs(sobelx)
sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)
sobely = cv2.convertScaleAbs(sobely)
sobelxy = cv2.addWeighted(sobelx,0.5,sobely,0.5,0)
cv_show(sobelxy,'sobelxy')
```

img = cv2.imread('lena.jpg',cv2.IMREAD_GRAYSCALE)

sobelxy=cv2.Sobel(img,cv2.CV_64F,1,1,ksize=3)
sobelxy = cv2.convertScaleAbs(sobelxy) 
cv_show(sobelxy,'sobelxy')

### 图像梯度-Scharr算子

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\scharr.png)

### 图像梯度-laplacian算子

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\l.png)


```python
#不同算子的差异
img = cv2.imread('lena.jpg',cv2.IMREAD_GRAYSCALE)
sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)
sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)
sobelx = cv2.convertScaleAbs(sobelx)   
sobely = cv2.convertScaleAbs(sobely)  
sobelxy =  cv2.addWeighted(sobelx,0.5,sobely,0.5,0)  

scharrx = cv2.Scharr(img,cv2.CV_64F,1,0)
scharry = cv2.Scharr(img,cv2.CV_64F,0,1)
scharrx = cv2.convertScaleAbs(scharrx)   
scharry = cv2.convertScaleAbs(scharry)  
scharrxy =  cv2.addWeighted(scharrx,0.5,scharry,0.5,0) 

laplacian = cv2.Laplacian(img,cv2.CV_64F)
laplacian = cv2.convertScaleAbs(laplacian)   

res = np.hstack((sobelxy,scharrxy,laplacian))
cv_show(res,'res')
```


```python
img = cv2.imread('lena.jpg',cv2.IMREAD_GRAYSCALE)
cv_show(img,'img')
```

### Canny边缘检测

- 1)        使用高斯滤波器，以平滑图像，滤除噪声。

- 2)        计算图像中每个像素点的梯度强度和方向。

- 3)        应用非极大值（Non-Maximum Suppression）抑制，以消除边缘检测带来的杂散响应。

- 4)        应用双阈值（Double-Threshold）检测来确定真实的和潜在的边缘。

- 5)        通过抑制孤立的弱边缘最终完成边缘检测。

#### 1:高斯滤波器

![title](C:\Users\Administrator\Downloads\图像处理\canny_1.png)

#### 2:梯度和方向

![title](C:\Users\Administrator\Downloads\图像处理\canny_2.png)

#### 3：非极大值抑制

![title](C:\Users\Administrator\Downloads\图像处理\canny_3.png)

![title](C:\Users\Administrator\Downloads\图像处理\canny_6.png)

#### 4：双阈值检测

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\canny_5.png)


```python
img=cv2.imread("lena.jpg",cv2.IMREAD_GRAYSCALE)

v1=cv2.Canny(img,80,150)
v2=cv2.Canny(img,50,100)

res = np.hstack((v1,v2))
cv_show(res,'res')

```


```python
img=cv2.imread("car.png",cv2.IMREAD_GRAYSCALE)

v1=cv2.Canny(img,120,250)
v2=cv2.Canny(img,50,100)

res = np.hstack((v1,v2))
cv_show(res,'res')
```

### 图像金字塔

- 高斯金字塔
- 拉普拉斯金字塔

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\Pyramid_1.png)

#### 高斯金字塔：向下采样方法（缩小）

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\Pyramid_2.png)

#### 高斯金字塔：向上采样方法（放大）

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\Pyramid_3.png)


```python
img=cv2.imread("AM.png")
cv_show(img,'img')
print (img.shape)
```

    (442, 340, 3)



```python
up=cv2.pyrUp(img)
cv_show(up,'up')
print (up.shape)
```

    (884, 680, 3)



```python
down=cv2.pyrDown(img)
cv_show(down,'down')
print (down.shape)
```

    (221, 170, 3)



```python
up2=cv2.pyrUp(up)
cv_show(up2,'up2')
print (up2.shape)
```

    (1768, 1360, 3)



```python
up=cv2.pyrUp(img)
up_down=cv2.pyrDown(up)
cv_show(up_down,'up_down')
```


```python
cv_show(np.hstack((img,up_down)),'up_down')
```


```python
up=cv2.pyrUp(img)
up_down=cv2.pyrDown(up)
cv_show(img-up_down,'img-up_down')
```

#### 拉普拉斯金字塔

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\Pyramid_4.png)


```python
down=cv2.pyrDown(img)
down_up=cv2.pyrUp(down)
l_1=img-down_up
cv_show(l_1,'l_1')
```

### 图像轮廓

#### cv2.findContours(img,mode,method)

mode:轮廓检索模式

- RETR_EXTERNAL ：只检索最外面的轮廓；
- RETR_LIST：检索所有的轮廓，并将其保存到一条链表当中；
- RETR_CCOMP：检索所有的轮廓，并将他们组织为两层：顶层是各部分的外部边界，第二层是空洞的边界;
- RETR_TREE：检索所有的轮廓，并重构嵌套轮廓的整个层次;

method:轮廓逼近方法

- CHAIN_APPROX_NONE：以Freeman链码的方式输出轮廓，所有其他方法输出多边形（顶点的序列）。
- CHAIN_APPROX_SIMPLE:压缩水平的、垂直的和斜的部分，也就是，函数只保留他们的终点部分。

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\chain.png)

为了更高的准确率，使用二值图像。


```python
img = cv2.imread('contours.png')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
cv_show(thresh,'thresh')
```


```python
binary, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)
```

绘制轮廓


```python
cv_show(img,'img')
```


```python
#传入绘制图像，轮廓，轮廓索引，颜色模式，线条厚度
# 注意需要copy,要不原图会变。。。
draw_img = img.copy()
res = cv2.drawContours(draw_img, contours, -1, (0, 0, 255), 2)
cv_show(res,'res')
```


```python
draw_img = img.copy()
res = cv2.drawContours(draw_img, contours, 0, (0, 0, 255), 2)
cv_show(res,'res')
```

#### 轮廓特征


```python
cnt = contours[0]
```


```python
#面积
cv2.contourArea(cnt)
```


    8500.5




```python
#周长，True表示闭合的
cv2.arcLength(cnt,True)
```




    437.9482651948929



#### 轮廓近似

![title](D:\code\Opencv图像处理\opencv_code\Opencv图像处理框架\contours3.png)


```python
img = cv2.imread('contours2.png')

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
binary, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)
cnt = contours[0]

draw_img = img.copy()
res = cv2.drawContours(draw_img, [cnt], -1, (0, 0, 255), 2)
cv_show(res,'res')
```


```python
epsilon = 0.15*cv2.arcLength(cnt,True) 
approx = cv2.approxPolyDP(cnt,epsilon,True)

draw_img = img.copy()
res = cv2.drawContours(draw_img, [approx], -1, (0, 0, 255), 2)
cv_show(res,'res')
```

边界矩形


```python
img = cv2.imread('contours.png')

gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
binary, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)
cnt = contours[0]

x,y,w,h = cv2.boundingRect(cnt)
img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)
cv_show(img,'img')
```


```python
area = cv2.contourArea(cnt)
x, y, w, h = cv2.boundingRect(cnt)
rect_area = w * h
extent = float(area) / rect_area
print ('轮廓面积与边界矩形比',extent)
```




    0.5154317244724715



外接圆


```python
(x,y),radius = cv2.minEnclosingCircle(cnt) 
center = (int(x),int(y)) 
radius = int(radius) 
img = cv2.circle(img,center,radius,(0,255,0),2)
cv_show(img,'img')
```

### 傅里叶变换

我们生活在时间的世界中，早上7:00起来吃早饭，8:00去挤地铁，9:00开始上班。。。以时间为参照就是时域分析。

但是在频域中一切都是静止的！

https://zhuanlan.zhihu.com/p/19763358


### 傅里叶变换的作用

- 高频：变化剧烈的灰度分量，例如边界

- 低频：变化缓慢的灰度分量，例如一片大海

### 滤波

- 低通滤波器：只保留低频，会使得图像模糊

- 高通滤波器：只保留高频，会使得图像细节增强



- opencv中主要就是cv2.dft()和cv2.idft()，输入图像需要先转换成np.float32 格式。
- 得到的结果中频率为0的部分会在左上角，通常要转换到中心位置，可以通过shift变换来实现。
- cv2.dft()返回的结果是双通道的（实部，虚部），通常还需要转换成图像格式才能展示（0,255）。


```python
import numpy as np
import cv2
from matplotlib import pyplot as plt

img = cv2.imread('lena.jpg',0)

img_float32 = np.float32(img)

dft = cv2.dft(img_float32, flags = cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)
# 得到灰度图能表示的形式
magnitude_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))

plt.subplot(121),plt.imshow(img, cmap = 'gray')
plt.title('Input Image'), plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(magnitude_spectrum, cmap = 'gray')
plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])
plt.show()
```


![png](C:\Users\Administrator\Downloads\图像处理\output_112_0.png)



```python
import numpy as np
import cv2
from matplotlib import pyplot as plt

img = cv2.imread('lena.jpg',0)

img_float32 = np.float32(img)

dft = cv2.dft(img_float32, flags = cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)

rows, cols = img.shape
crow, ccol = int(rows/2) , int(cols/2)     # 中心位置

# 低通滤波
mask = np.zeros((rows, cols, 2), np.uint8)
mask[crow-30:crow+30, ccol-30:ccol+30] = 1

# IDFT
fshift = dft_shift*mask
f_ishift = np.fft.ifftshift(fshift)
img_back = cv2.idft(f_ishift)
img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])

plt.subplot(121),plt.imshow(img, cmap = 'gray')
plt.title('Input Image'), plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(img_back, cmap = 'gray')
plt.title('Result'), plt.xticks([]), plt.yticks([])

plt.show()                
```


![png](C:\Users\Administrator\Downloads\图像处理\output_113_0.png)



```python
img = cv2.imread('lena.jpg',0)

img_float32 = np.float32(img)

dft = cv2.dft(img_float32, flags = cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)

rows, cols = img.shape
crow, ccol = int(rows/2) , int(cols/2)     # 中心位置

# 高通滤波
mask = np.ones((rows, cols, 2), np.uint8)
mask[crow-30:crow+30, ccol-30:ccol+30] = 0

# IDFT
fshift = dft_shift*mask
f_ishift = np.fft.ifftshift(fshift)
img_back = cv2.idft(f_ishift)
img_back = cv2.magnitude(img_back[:,:,0],img_back[:,:,1])

plt.subplot(121),plt.imshow(img, cmap = 'gray')
plt.title('Input Image'), plt.xticks([]), plt.yticks([])
plt.subplot(122),plt.imshow(img_back, cmap = 'gray')
plt.title('Result'), plt.xticks([]), plt.yticks([])

plt.show()    
```

## yolov5

### 打开标注工具

```
labelimg
```

```
修改为识别yolo
```

## 数据集下载

```
https://universe.roboflow.com/
数据集下载: https://www.cvmart.net/dataSets  账号:mxy1143238608   mxy1q2w3e4r
https://aistudio.baidu.com/datasetoverview
```

## 手势识别，首部特征点识别

```
https://ai.google.dev/edge/mediapipe/solutions/guide?hl=zh-cn
```



## yolov9

### 创建python解释器

```
conda create -n yolov9 python=3.8
```

### 激活环境

```
conda activate yolov9
```

### 退出环境

```
conda deactivate
```

### 下载pythoch

```
conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia
-----------------------
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121 -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple --trusted-host=https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
```

### pythoch历史版本

```
https://pytorch.org/get-started/previous-versions/
```

### 下载yolo依赖包

```
pip install -r requirements.txt -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple --trusted-host=https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
```

## yolov10

```
训练物体：
yolo detect train data=D:\code\OpencvPeoject\yolov10\ultralytics\assets\vehicles\data.yaml model=yolov10n.pt epochs=10 batch=2 imgsz=640 device=0
```

## yolov10模型转换onnx

```
yolo export model=yolov10n.pt format=onnx opset=13 simplify
```

## 调用onnx模型识别推理(图片)

```python
import onnxruntime as ort
import numpy as np
import cv2

# 加载 ONNX 模型
session = ort.InferenceSession("yolov10n.onnx")

# 获取模型输入和输出的名字
input_name = session.get_inputs()[0].name
output_name = session.get_outputs()[0].name


# 预处理输入图像
def preprocess(image, input_size=(640, 640)):
    image_resized = cv2.resize(image, input_size)
    # cv2.imshow("image_resized", image_resized)
    image_transposed = image_resized.transpose(2, 0, 1)  # HWC to CHW
    image_normalized = image_transposed / 255.0  # Normalize to [0, 1]
    image_expanded = np.expand_dims(image_normalized, axis=0).astype(np.float32)
    return image_expanded


# 后处理输出
def postprocess(image, outputs, conf_threshold=0.5):
    boxes, scores, class_ids = outputs[0][:, :4], outputs[0][:, 4], outputs[0][:, 5].astype(int)
    h, w = image.shape[:2]
    text = ''
    # 遍历所有检测结果
    for box, score, class_id in zip(boxes, scores, class_ids):
        for b in box:
            x1, y1, x2, y2, a1, a2 = b
            print(b)
            if a1 > conf_threshold:
                x1 = int(x1 / 640 * w)
                y1 = int(y1 / 640 * h)
                x2 = int(x2 / 640 * w)
                y2 = int(y2 / 640 * h)
                print(x1, y1, x2, y2)
                # 绘制边框
                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                # 在框上方显示分类ID和置信度
                # label = f"Class {class_id}"
                if a2 == 5.:
                    text = 'bus'
                elif a2 == 0.:
                    text = 'person'
                cv2.putText(image, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return image

if __name__ == '__main__':

    # 加载并预处理图像
    image_path = r"D:\code\OpencvPeoject\yolov10\ultralytics\assets\bus.jpg"
    image = cv2.imread(image_path)
    input_image = preprocess(image)
    
    # 运行模型推理
    outputs = session.run([output_name], {input_name: input_image})
    # 后处理并展示标记好的图像
    marked_image = postprocess(image, outputs)

    # 展示图像
    cv2.imshow("Detected Image", marked_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

```

## 调用onnx模型推理视频

```python
import onnxruntime as ort
import numpy as np
import cv2

# 加载 ONNX 模型
session = ort.InferenceSession("yolov10n.onnx")

# 获取模型输入和输出的名字
input_name = session.get_inputs()[0].name
output_name = session.get_outputs()[0].name


# 预处理输入图像
def preprocess(image, input_size=(640, 640)):
    image_resized = cv2.resize(image, input_size)
    # cv2.imshow("image_resized", image_resized)
    image_transposed = image_resized.transpose(2, 0, 1)  # HWC to CHW
    image_normalized = image_transposed / 255.0  # Normalize to [0, 1]
    image_expanded = np.expand_dims(image_normalized, axis=0).astype(np.float32)
    return image_expanded


# 后处理输出
def postprocess(image, outputs, conf_threshold=0.5):
    boxes, scores, class_ids = outputs[0][:, :4], outputs[0][:, 4], outputs[0][:, 5].astype(int)
    h, w = image.shape[:2]
    text = ''
    # 遍历所有检测结果
    for box, score, class_id in zip(boxes, scores, class_ids):
        for b in box:
            x1, y1, x2, y2, a1, a2 = b
            print(b)
            if a1 > conf_threshold:
                x1 = int(x1 / 640 * w)
                y1 = int(y1 / 640 * h)
                x2 = int(x2 / 640 * w)
                y2 = int(y2 / 640 * h)
                print(x1, y1, x2, y2)
                # 绘制边框
                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                # 在框上方显示分类ID和置信度
                # label = f"Class {class_id}"
                if a2 == 5.:
                    text = 'bus'
                elif a2 == 0.:
                    text = 'person'
                cv2.putText(image, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return image


if __name__ == '__main__':
    # 打开视频文件或摄像头
    video_path = r"D:\code\OpencvPeoject\yolov10\ultralytics\assets\video\sd1660272102_2.mp4"  # 替换为你的视频路径
    cap = cv2.VideoCapture(video_path)
    while True:
        ret, frame = cap.read()
        input_image = preprocess(frame)

        # 运行模型推理
        outputs = session.run([output_name], {input_name: input_image})
        # 后处理并展示标记好的图像
        marked_image = postprocess(frame, outputs)

        # 展示图像
        cv2.imshow("Detected Image", marked_image)
        # 按 'q' 键退出
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    # 释放资源并关闭窗口
    cap.release()
    cv2.destroyAllWindows()

```

## yolov10调用(原生)

```python
from ultralytics import YOLOv10

# Load a pretrained YOLOv10n model
model = YOLOv10("yolov10n.pt")

# Perform object detection on an image
# results = model("test1.jpg")
results = model.predict(r"D:\code\OpencvPeoject\yolov10\ultralytics\assets\test1.jpg")
print(results)
for result in results:
    boxes = result.boxes
    for box in boxes:
        # print(box)
        # 识别出的左上角，右下角坐标
        print(box.xyxy[0].tolist())
        class_index = int(box.cls[0])
        # 识别出的类别
        print(result.names[class_index])
# Display the results
results[0].show()
```

## yolov10调用(supervision)

```python
import cv2
import supervision as sv
from ultralytics import YOLOv10

# Load a pretrained YOLOv10n model
# D:\code\OpencvPeoject\yolov10\runs\detect\train4\weights\best.pt
model = YOLOv10(r"D:\code\OpencvPeoject\yolov10\runs\detect\train4\weights\best.pt")

# Perform object detection on an image
image = cv2.imread(r'D:\code\OpencvPeoject\yolov10\ultralytics\assets\test1.jpg')

results = model(image)[0]

detections = sv.Detections.from_ultralytics(results)

# 方框绘制信息
box_annotator = sv.BoxAnnotator()
# 角点边界框绘制信息
corner_annotator = sv.BoxCornerAnnotator(corner_length=10, thickness=1, color=sv.Color(r=0, g=255, b=255))
# 三角形边界框绘制信息
triangle_annotator = sv.TriangleAnnotator(base=30, height=30, position=sv.Position['TOP_CENTER'])
# 标签信息
label_annotator = sv.LabelAnnotator()

labels = [
    f'{class_name} {confidence:.2f}'
    for class_name, confidence in zip(detections['class_name'], detections.confidence)
]
# 标注识别框
annotated_image = box_annotator.annotate(scene=image.copy(), detections=detections)
corner_image = corner_annotator.annotate(scene=image.copy(), detections=detections)
triangle_image = triangle_annotator.annotate(scene=image.copy(), detections=detections)
# 标注识别标签和置信度
annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)
cv2.imwrite('image.jpg', annotated_image)
cv2.imwrite('image1.jpg', corner_image)
cv2.imwrite('image2.jpg', triangle_image)

```

## supervision中标注器（Annotator）

```
BlurAnnotator: 用于模糊图像的某个区域。例如，可以模糊敏感信息或不想展示的区域。

BoundingBoxAnnotator: 用于绘制边界框（Bounding Box），通常用于显示物体检测结果。边界框是一个矩形框，框住图像中的特定对象。

BoxAnnotator: 类似于 BoundingBoxAnnotator，用于绘制矩形框，但可能提供更多的自定义选项（如颜色、厚度）。

BoxCornerAnnotator: 用于在边界框的角落上绘制小标记或点。这些标记可以帮助更好地展示边界框的位置和大小。

CircleAnnotator: 用于在图像上绘制圆形，通常用来标记特定的点或区域。

ColorAnnotator: 用于在图像上显示颜色信息，可能用于显示分类结果或其他需要颜色区分的信息。

CropAnnotator: 用于裁剪图像的某个区域，通常用于关注图像中的特定部分。

DotAnnotator: 用于在图像上绘制小点，可以用来标记关键点或特定位置。

EllipseAnnotator: 用于在图像上绘制椭圆形，适用于标记类似球形或椭圆形的对象。

HaloAnnotator: 用于在对象周围绘制光环（Halo）效果，这有助于突出显示特定对象。

HeatMapAnnotator: 用于在图像上绘制热图（Heatmap），通常用于显示预测的置信度或注意力区域。

LabelAnnotator: 用于在图像上添加文本标签，适用于为对象或区域提供描述性文字。

MaskAnnotator: 用于在图像上绘制分割掩码（Mask），通常用在语义分割任务中，显示不同对象或区域的分类。

OrientedBoxAnnotator: 用于绘制方向框（Oriented Bounding Box），与普通的边界框不同，它们可以有任意的旋转角度，适合标注倾斜或旋转的对象。

PercentageBarAnnotator: 用于绘制百分比条，通常用来表示某些统计数据或置信度分数。

PixelateAnnotator: 用于将图像的某个区域像素化（Pixelate），常用于隐私保护（比如打码面部区域）。

PolygonAnnotator: 用于绘制多边形，适合用于标注不规则形状的对象，如道路、建筑等。

RichLabelAnnotator: 类似于 LabelAnnotator，但提供更丰富的样式和格式选项（如不同的字体、颜色等）。

RoundBoxAnnotator: 用于绘制带有圆角的矩形框。

TraceAnnotator: 用于绘制路径或轨迹，适用于显示物体的运动轨迹或轮廓。

TriangleAnnotator: 用于在图像上绘制三角形，适用于标记三角形区域或物体。
```



## 使用yolo系列识别视频(单独项目yolov5，yolov9)

```python
import cv2
import torch


class PPE:
    def __init__(self):
        # 注意需要与使用的对应yolo项目同级目录
        self.model = torch.hub.load('../yolov5', 'custom', path='./yolov5s.pt', source='local')
        self.model.conf = 0.4
        video_path = './sd1660272102_2.mp4'
        self.cap = cv2.VideoCapture(video_path)

    def detect(self):
        while True:
            ret, frame = self.cap.read()

            # 画面反转
            # frame = cv2.flip(frame, 1)
            # 画面转为RGB格式
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            # 推理过程
            results = self.model(frame_rgb)
            results_np = results.pandas().xyxy[0].to_numpy()
            print(results_np)

            # 绘制边界框
            for box in results_np:
                l, t, r, b = box[:4].astype('int')
                label_id = box[5]
                if label_id == 0:
                    cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)
                else:
                    cv2.rectangle(frame, (l, t), (r, b), (255, 0, 255), 2)
            # 显示画面
            cv2.imshow('demo', frame)

            if cv2.waitKey(10) & 0xff == ord('q'):
                break
        self.cap.release()
        cv2.destroyAllWindows()


ppe = PPE()
ppe.detect()

```

## 通过程序句柄获取截图

```python
import pygetwindow as gw
from PIL import ImageGrab

import win32gui
import win32ui
import win32con
from PIL import Image
import time

for prc in gw.getAllWindows():
    print(prc)


def get_window_handle(window_name):
    hwnd = win32gui.FindWindow(None, window_name)
    if hwnd:
        print(f"Window handle for '{window_name}' is: {hwnd}")
    else:
        print(f"Window '{window_name}' not found.")
    return hwnd


def screenshot_window(hwnd):
    # 获取窗口的设备上下文
    window_dc = win32gui.GetWindowDC(hwnd)
    mfc_dc = win32ui.CreateDCFromHandle(window_dc)
    save_dc = mfc_dc.CreateCompatibleDC()

    # 获取窗口的宽度和高度
    left, top, right, bottom = win32gui.GetWindowRect(hwnd)
    width = right - left
    height = bottom - top

    # 创建位图对象
    bitmap = win32ui.CreateBitmap()
    bitmap.CreateCompatibleBitmap(mfc_dc, width, height)
    save_dc.SelectObject(bitmap)

    # 将窗口内容复制到位图对象
    save_dc.BitBlt((0, 0), (width, height), mfc_dc, (0, 0), win32con.SRCCOPY)

    # 将位图转为图像数据
    bmpinfo = bitmap.GetInfo()
    bmpstr = bitmap.GetBitmapBits(True)

    img = Image.frombuffer(
        'RGB',
        (bmpinfo['bmWidth'], bmpinfo['bmHeight']),
        bmpstr, 'raw', 'BGRX', 0, 1
    )

    # 释放资源
    win32gui.DeleteObject(bitmap.GetHandle())
    save_dc.DeleteDC()
    mfc_dc.DeleteDC()
    win32gui.ReleaseDC(hwnd, window_dc)

    return img


def save_screenshot(img, save_path):
    img.save(save_path)


if __name__ == '__main__':
    window_name = "虎牙直播"  # 这里替换为目标窗口的名称
    hwnd = get_window_handle(window_name)

    if hwnd:
        while True:
            img = screenshot_window(hwnd)
            save_path = "screenshot.png"  # 保存截图的位置
            save_screenshot(img, save_path)
            print(f"Screenshot saved to {save_path}")

            time.sleep(1)  # 每隔 1 秒截图一次，调整频率以满足需求
    else:
        print("Failed to find the window handle.")
```

## 获取句柄后鼠标点击

```python
import pygetwindow as gw
from PIL import ImageGrab

import win32gui
import win32api
import win32con

for prc in gw.getAllWindows():
    print(prc)

hwnd = win32gui.FindWindow(None, '人工智能笔记.md - Typora')
print(hwnd)
x = 772
y = 15
# 将窗口置于前台
win32gui.SetForegroundWindow(hwnd)
# 获取窗口的左上角坐标
left, top, right, bottom = win32gui.GetWindowRect(hwnd)
print(left, top, right, bottom)
# 1652,361

# 计算相对于屏幕的绝对坐标
abs_x = left + x
abs_y = top + y
print(abs_x,abs_y)
# 移动鼠标到指定位置并点击
win32api.SetCursorPos((abs_x, abs_y))
win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)
win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)
```

